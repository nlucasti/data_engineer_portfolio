# Data Warehouse
### A Udacity Project

## About the Dataset
The data used for this project is made up of two sets. One set consists of subset of data from the Million Song Dataset. Each file is in JSON format and contains data about each song. The other set consist of log files in JSON format. These log files are generated by a random event simulator based on the songs of the above data set. All of this data is stored on Amazon S3, a cloud-based storage drive. This allows web-based operations which will offload the processing to cloud-computers. 

## Purpose
The purpose of this analysis was to build a database for a streaming app called Sparkify. The company wants to understand what songs users listen to. Before this project, the company had a lot of data, however they had no easy way to query their data or even examine it on a large scale. Therefore, the need for a database with query-based optimization was necessary. Sparkify also wanted the database operating on Amazon Web Services so that they could deploy EC2 nodes as needed for analysis. This will save the company money on CapEx costs. 

## Database Design
A star schema was used for this dataset because the data wasn't overly complex, yet there had to be a way to access each dimension table. At first we created a staging table for the data on Amazon S3, this allowed us to copy the data directly into the table. Using the staging tables, we can populate the fact and dimension tables much faster and upsert when needed. In terms of the fact and dimension tables, we use the songplay table as the fact table and each of the other tables (users, songs, artists, and time) are our dimension tables. We do this because the most important data for Sparkify is the songplay data. Therefore, queries through this table are optimized based on the fact that they don't rely on joins. I then optimized the dimension tables using keys so that in the event that joins are required, they can be completed faster. One problem I ran into was that AWS Redshift does not have built in support for upserting the data. Therefore, logic had to be created to prevent conflicting rows.
